{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFaceDeployment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbX63aiHNYoE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "s6y8i8xINpJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30d9d45-d54c-411e-abfa-a8c0710f93a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 21.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2022.5.18.1)\n",
            "Installing collected packages: pyyaml, huggingface-hub\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWgRqgmMN-k8",
        "outputId": "fd11fabe-f82e-4c2f-83d7-029cce358c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n",
            "        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n",
            "        \n",
            "Token: \n",
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create DialoGPT-small-TChalla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsxgejwXOI1G",
        "outputId": "7572159d-1bd6-4515-cdb2-20072b090491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90mgit version 2.17.1\u001b[0m\n",
            "Error: unknown flag: --version\n",
            "\n",
            "\u001b[90mSorry, no usage text found for \"git-lfs\"\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1mCodeMaestro/DialoGPT-small-TChalla\u001b[0m\n",
            "Proceed? [Y/n] y\n",
            "409 Client Error: Conflict for url: https://huggingface.co/api/repos/create - You already created this model repo\n",
            "\u001b[1m\u001b[31m{\"error\":\"You already created this model repo\",\"url\":\"https://huggingface.co/CodeMaestro/DialoGPT-small-TChalla\"}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install git-lfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXlq9ObZPEKz",
        "outputId": "d209a6c9-32d0-407b-dc2b-be0a8ff8adf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This allows for a push of models and lfs means large files storage\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "KaQ9A6WOQfQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to reacquire the token just use\n",
        "!cat /root/.huggingface/token"
      ],
      "metadata": {
        "id": "2p77yJl2RYii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://CodeMaestro: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@huggingface.co/CodeMaestro/DialoGPT-small-TChalla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNc3LkAqQMEd",
        "outputId": "ac66bea4-930f-47e5-e7ee-160879e612b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DialoGPT-small-TChalla'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 17 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt99ViozhmP7",
        "outputId": "e2eb9b0f-20cc-4804-f0c9-a4d7ecf69935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DialoGPT-small-TChalla\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LYBigTGgLDq",
        "outputId": "0b3691a5-f446-4caf-b632-867bea55213d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/output-small/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbrG9inzeCYJ",
        "outputId": "8a909434-f84e-4609-d89f-e9e6373607d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t  pytorch_model.bin\t   tokenizer.json\n",
            "eval_results.txt  special_tokens_map.json  training_args.bin\n",
            "merges.txt\t  tokenizer_config.json    vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now during the training of the model for the attributes we stored the model in a dir called output-small\n",
        "!mv /content/drive/My\\ Drive/output-small/* DialoGPT-small-TChalla/\n"
      ],
      "metadata": {
        "id": "Q1IbBCYmROVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"DialoGPT-small-TChalla\")"
      ],
      "metadata": {
        "id": "4a6Wf15ESgJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the change to the DialoGPT-small-TChalla dir is cz after we move the content of the trained mdoel there we are going to push from there"
      ],
      "metadata": {
        "id": "EtlyULgWizST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1J09ewJSoD7",
        "outputId": "5494da39-e4c7-4748-d31d-bf25cdd5df7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvpSwfNhjCU-",
        "outputId": "83445d55-a354-430f-baf2-ade5518c8bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t  pytorch_model.bin\t   tokenizer_config.json  vocab.json\n",
            "eval_results.txt  README.md\t\t   tokenizer.json\n",
            "merges.txt\t  special_tokens_map.json  training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEjP_k5qjNOp",
        "outputId": "f8f8f470-7cd8-44f0-fa5d-42682d63c7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DialoGPT-small-TChalla\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Che_3SD3jSSW",
        "outputId": "973729a8-8b0c-4cac-d788-af4e6d6af260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   config.json\u001b[m\n",
            "\t\u001b[31mmodified:   eval_results.txt\u001b[m\n",
            "\t\u001b[31mmodified:   pytorch_model.bin\u001b[m\n",
            "\t\u001b[31mmodified:   tokenizer_config.json\u001b[m\n",
            "\t\u001b[31mmodified:   training_args.bin\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "vqNL3AfWjXhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding my credentials so that I never have to do this again and this are hugging face credentials\n",
        "!git config --global user.email \"francismurithi475@gmail.com\"\n",
        "!git config --global user.name \"CodeMaestro\""
      ],
      "metadata": {
        "id": "BcgQbiO2jjab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Initial Commit\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_tAsKdfke_j",
        "outputId": "07100266-5e56-4c87-e728-d0b926fd01fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 0b28b71] Initial Commit\n",
            " 5 files changed, 9 insertions(+), 9 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c81ZMkmekl-r",
        "outputId": "5d7946af-1fe4-4795-c721-ede9d629b33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS: (2 of 2 files) 1.35 GB / 1.35 GB\n",
            "Counting objects: 7, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (7/7), 802 bytes | 802.00 KiB/s, done.\n",
            "Total 7 (delta 3), reused 0 (delta 0)\n",
            "remote: Enforcing permissions...\u001b[K\n",
            "remote: Allowed refs: all\u001b[K\n",
            "To https://huggingface.co/CodeMaestro/DialoGPT-small-TChalla\n",
            "   5f3724c..0b28b71  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JBiDyPBdkq1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}